---
title: "Ceci n'est pas une %>%: <br>Exploring Your Data with R"
author: ""

date: "Fall, 2015"
output: 
  ioslides_presentation: 
    smaller: no
    widescreen: yes
    css: slideStyles.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning=FALSE, R.options=list(width=120))
library(dplyr); library(magrittr)
```


## Goals
>- Introduce newer approaches to data wranging, scrubbing, manipulation etc.

>- Show the benefits of <span class='emph'>*piping*</span> code

>- Put it all together with some newer visualization packages 


## Outline 
Newer approaches to data wrangling

- Introduction to <span class='pack'>plyr</span> <span class='pack'>dplyr</span> and <span class='pack'>tidyr</span>
- Subsetting rows
- Subsetting columns
- Reshaping data
- Generating new data
- Grouping and summarizing

Nothin's gonna stop the flow

- Piping with the <span class='pack'>magrittr</span> package

Quick interactive visualizations

- <span class='pack'>ggvis</span>, <span class='pack'>htmlwidgets</span>
    
    

# Newer approaches to <br> data wrangling
## Newer approaches to data wrangling
A starting example

Let's say we want to select from our data the following variables

  - The variables **X1:X10**, which are not all together, and there are many more *X* columns
  - The variables **var1** and **var2**, which are the only *var* variables in the data
  - Any variable that starts with **XYZ**
    
How might we go about this?


## Some base R approaches

Tedious, or typically two steps just to get the columns you want.

```{r baseRexample1, eval=FALSE}
# numeric indexes; not conducive to readibility or reproducibility
newData = oldData[,c(1,2,3,4, etc.)]

# explicitly by name; fine if only a handful; not pretty
newData = oldData[,c('X1', 'X2', etc.)]

# two step with grep; regex difficult to read/understand
cols = c(paste0('X', 1:10), 'var1', 'var2', grep(colnames(oldData), '^XYZ', value=T))
newData = oldData[,cols]

# or via subset
newData = subset(oldData, select = cols)
```


## More
What if you also want observations where **Z** is **Yes**, Q is **No**, and only the last 50 of those results, ordered by **var1** (descending)?

```{r baseRexample2, eval=FALSE}
# three operations and overwriting or creating new objects if we want clarity
newData = newData[oldData$Z == 'Yes' & oldData$Q == 'No',]
newData = tail(newData, 50)
newData = newdata[order(newdata$var1, decreasing=T),]
```

And this is for fairly straightforward operations.


## An alternative

```{r pipeExample, eval=FALSE}
newData = oldData %>% 
  filter(Z == 'Yes', Q == 'No') %>% 
  select(num_range('X', 1:10), contains('var'), starts_with('XYZ')) %>% 
  tail(50) %>% 
  arrange(desc(var1))
```


## An alternative

Even though the initial base R approach depicted is probably more concise than many would do on their own, it still is: 

>- noisier
>- less legible
>- less amenable to additional data changes
>- requires esoteric knowledge (e.g. regular expressions)
>- often requires new objects (even if we just want to explore)



# Another example...
## Start with a string, end with a map

```{r wikileafletNoEval, eval=FALSE, echo=-c(1:6)}
packs = c('magrittr', 'rvest', 'dplyr', 'stringr' ,'leaflet', 'ggvis')
sapply(packs, library, character.only=T)

# a color palette to be used later
pal = colorNumeric(palette = c('Red', 'White', 'Navy'), test0$popDiff)  

wikiURL = 'https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population'

# Let's go!
wikiURL %>% 
  read_html %>%                                                                     # parse the html
  html_node(css='.wikitable.sortable') %>%                                          # grab a class of object
  html_table %>%                                                                    # convert table to data.frame
  sapply(function(x) repair_encoding(as.character(x), 'UTF-8')) %>%                 # repair encoding; makes a matrix
  data.frame %>%                                                                    # back to df
  mutate(City = str_replace(City, '\\[(.*?)\\]', ''),                               # remove footnotes
         latlon = sapply(str_split(Location, '/'), last),                           # split up location (3 parts)
         latlon = str_extract_all(latlon, '[-|[0-9]]+\\.[0-9]+'),                   # grab any that start with - or number
         lat = sapply(latlon, first),                                               # grab latitudes
         lon = sapply(latlon, nth, 2),                                              # grab longitude
         population2014 = as.numeric(str_replace_all(X2014.estimate, ',', '')),     # remove commas from numbers (why do people do this?)
         population2010 = as.numeric(str_replace_all(X2010.Census, ',', '')),       # same for 2010
         popDiff  = round(population2014/population2010 - 1, 2)*100) %>%            # create percentage difference
```

## Cont'd.

```{r wikileafletNoEval2, eval=FALSE}
  select(-latlon, -Location) %>%                                                    # remove stuff we wouldn't ever use
  filter(as.numeric(as.character(X2014.rank)) <= 50)  %>%                           # top 50
  leaflet %>%                                                                       # map out
  addProviderTiles("CartoDB.DarkMatterNoLabels") %>% 
  setView(-94, 35, zoom = 4) %>% 
  addCircleMarkers(~lon, ~lat,
                   radius=  ~scales::rescale(popDiff, c(1, 10)),
                   fillColor=  ~pal(popDiff), stroke = FALSE, fillOpacity = .85,
                   popup=  ~paste(City, paste0(popDiff, '%')))
```


## And the result...

```{r wikileaflet, eval=TRUE, echo=FALSE}
# packs = c('magrittr', 'rvest', 'dplyr', 'stringr' ,'leaflet', 'ggvis')
# sapply(packs, library, character.only=T); DONT USE
library(magrittr); library(rvest); library(dplyr); library(stringr);
library(leaflet)

'https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population' %>% 
  read_html %>% 
  html_node(css='.wikitable.sortable') %>% 
  html_table %>% 
  sapply(function(x) repair_encoding(as.character(x), 'UTF-8'), simplify=F) %>%
  data.frame %>%  
  mutate(City = str_replace(City, '\\[(.*?)\\]', ''),
         latlon = sapply(str_split(Location, '/'), last), 
         latlon = str_extract_all(latlon, '[-|[0-9]]+\\.[0-9]+'), 
         lat = sapply(latlon, first),
         lon = sapply(latlon, nth, 2), 
         population2014 = as.numeric(str_replace_all(X2014.estimate, ',', '')),
         population2010 = as.numeric(str_replace_all(X2010.Census, ',', '')),
         popDiff  = round(population2014/population2010 - 1, 2)*100) %T>% 
  select(-latlon, -Location) %>% 
  filter(as.numeric(as.character(X2014.rank)) <= 50)  %>% 
  leaflet %>% 
  addProviderTiles("CartoDB.DarkMatterNoLabels") %>% 
  setView(-94, 35, zoom = 4) %>% 
  addCircleMarkers(~lon, ~lat,
                   radius=  ~scales::rescale(popDiff, c(2, 11)),
                   fillColor=  ~colorNumeric(palette = c('Red', 'White', 'Navy'), popDiff)(popDiff), 
                   stroke = FALSE, fillOpacity = .85,
                   popup=  ~paste(City, paste0(popDiff, '%')))
```


## 

- In the interests of your own code, the previous is not recommended.

>- It serves as an illustration of what's possible.


## Newer approaches to data wrangling
Over the past couple of years, a handful of packages have been put out that make data management within R noticeably easier

We will focus on <span class='pack'>plyr</span>, <span class='pack'>dplyr</span>, and <span class='pack'>tidyr</span>

But others, e.g. <span class='pack'>data.table</span>, take different approaches and may be useful as well

Newer visualization packages take advantage of these approaches to data manipulation

- Makes it easier to explore your data visually



# A provocation

```{r provocation1, eval=F, echo=T}
c('Ceci', "n'est", 'pas', 'une', 'pipe!') %>%
{
  .. <-  . %>%
    if (length(.) == 1)  .
    else paste(.[1], '%>%', ..(.[-1]))
  ..(.)
} 
```

# 

```{r provocation2, eval=T, echo=T}
c('Ceci', "n'est", 'pas', 'une', 'pipe!') %>%
{
  .. <-  . %>%
    if (length(.) == 1)  .
    else paste(.[1], '%>%', ..(.[-1]))
  ..(.)
} 
```



# Your turn
## Your turn
Let's get to it!

>- Use a base R dataset
    - Examples: iris, mtcars, faithful or state.x77
>- As an exercise, pipe to something like the <span class='func'>summary</span>, <span class='func'>plot</span> or <span class='func'>cor</span> (if all numeric) as follows:

```{r yourturnPipe, eval=FALSE}
data %>% 
  function
```

>- If the function you use has additional arguments you want to try, put those arguments in parentheses:

```{r pipewithargs, eval=FALSE}
data %>% 
  function(arg='blah')
```
Note that Ctrl+Shft+m is the shortcut to make the %>% pipe.

# Data Wrangling

# Generating New Data
## Generating New Data

As is often the case, there are times when we want to calculate new variables based upon existing ones, or perhaps make changes to ones we have.

We can use mutate or transmute for this.

>- <span class='func'>mutate</span> appends to current data
>- <span class='func'>mutate_each</span> will apply a function over multiple columns
>- <span class='func'>transmute</span> will return only the newly created data

First, let's scrape some data:

```{r basketballDataScrape, cache=TRUE, message=FALSE, echo=-1}
library(rvest); library(dplyr); library(magrittr); library(tidyr)
url = "http://www.basketball-reference.com/leagues/NBA_2015_totals.html?lid=header_seasons"
bball = read_html(url) %>% 
  html_nodes("table#totals") %>% 
  html_table %>% 
  data.frame %>% 
  filter(Rk != "Rk")
```

## Generating New Data
The data is currently all character strings.

We'll use <span class='func'>mutate_each</span> to make every column numeric except for Player, Pos, and Tm.

```{r mutateach, cache=TRUE}
bball %<>% 
  mutate_each(funs(as.numeric), -Player, -Pos, -Tm)   

glimpse(bball)
```


## Generating New Data

A common situation, creating composites of existing variables.

```{r mutate, cache=TRUE}
bball = bball %>% 
  mutate(trueShooting = round(PTS / (2 * (FGA + (.44 * FTA))), 2),
         effectiveFG = round((FG + (.5 * X3P)) / FGA, 2), 
         shootingDif = trueShooting - FG.)

summary(select(bball, shootingDif))  # select and others don't have to be piped to use
```


## Generating New Data

Sometimes we want to combine (or split) variables...
<span class='func'>unite</span> creates a new variable as the string combination of others.

- essentially <span class='func'>paste</span>

<span class='func'>separate</span> does the opposite.

```{r tidyrUnite, cache=TRUE}
library(tidyr)
bball %>% 
  unite("posTeam", Pos, Tm) %>% 
  select(1:5) %>% 
  head
```


## Generating New Data
Separate player into first and last names based on where the space occurs.

```{r tidyrSpread, cache=TRUE}
library(tidyr)
bball %>% 
  separate(Player, into=c('firstName', 'lastName'), sep=' ') %>% 
  select(1:5) %>% 
  head
```

# Your turn
## Your turn

Data: state.x77

0. Convert to <span class='func'>data.frame</span>
1. Create a variable that's the <span class='func'>log</span> of population
2. Create **curLifeExp** as Life Expectancy + 5
3. summarize the data


# Selecting Variables
## Selecting Variables

There are times when you do not want to look at the entire dataset, but instead want to focus on a few key variables.

Although this is easily handled in base R (as shown earlier), it can often more clearly accomplished using select in <span class='pack'>dplyr</span>

The following lets us look at the data clearly, without having to create objects, use quotes etc.

```{r select1, cache=TRUE}
bball %>% 
  select(Player, Tm, Pos, MP, trueShooting, effectiveFG, PTS) %>% 
  summary
```


## Selecting Variables
That works great, but now we need to drop some of those variables to look at correlations.

```{r select2, cache=TRUE}
scoringDat = bball %>% 
  select(Player, Tm, Pos, MP, trueShooting, effectiveFG, PTS)

scoringDat %>% 
  select(-Player, -Tm, -Pos) %>% 
  cor(use='complete') %>% 
  round(2)
```


## Selecting Variables
Sometimes, we have a lot of variables to select. If they have a common naming scheme, this becomes very easy.

```{r select3, cache=TRUE}
bball %>% 
  select(Player, contains("3P"), ends_with("RB")) %>% 
  arrange(desc(X3P.1, TRB)) %>% 
  head
```



# Filtering Observations
## Filtering Observations

Recall this bit of code?

```{r bballRecall, eval=FALSE}
bball = html(url) %>% 
  html_nodes("table#totals") %>% 
  html_table %>% 
  data.frame %>% 
  filter(Rk != "Rk")
```

You will notice the filter line at the end.

We sometimes want to see a very specific portion of the data.


## Filtering Observations
>- <span class='func'>filter</span> returns rows with matching conditions.
>- <span class='func'>slice</span> allows for a numeric indexing approach.

>- Say we want too look at forwards over the age of 35...

```{r filter1, eval=FALSE}
bball %>% 
  filter(Age > 35, Pos == "SF" | Pos == "PF")
```

>- or the first 10 rows...

```{r filter2, eval=FALSE}
bball %>% 
  slice(1:10)
```


## Filtering Observations
This can be done with things that are created on the fly...

```{r uniteFilterArrange, cache=TRUE}
bball %>% 
  unite_("posTeam", c("Pos", "Tm")) %>% 
  filter(posTeam == "PF_SAS") %>% 
  arrange(desc(PTS/PF)) %>% 
  select(1:10)
```

# Your turn
## Your turn
A brief exercise:

1. filter the iris data set to only the `r "virginica"` species
2. show only **Petal.Length** and **Petal.Width** var
3. bonus: redo, but instead filter if the ratio of **Petal.Length** to **Petal.Width** is greater than 5. Which species do these observations belong to?



# Reshaping Data
## Reshaping Data

Depending upon your analytical or visualization needs, sometimes you need to reshape your data.

Reshaping can take many forms. You might need to reshape your data from wide format to long format.

Or, maybe you need to split or combine variables.

Either way, R has you covered.

## Wide to Long

We are going to use the <span class='pack'>tidyr</span> package to make this data go from wide to long.

The function of note is <span class='func'>gather</span>

- **key** is the new variable name
- **value** is the name of the 

```{r wide2long, eval=TRUE, cache=TRUE, echo=-c(1:2)}
library(tidyr)

bballLong = bball %>% 
  select(Player, Tm, FG., X3P, X2P.1, trueShooting, effectiveFG) %>%
  rename(fieldGoalPerc = FG., threePointPerc = X3P, twoPointPerc = X2P.1) %>% 
  mutate(threePointPerc = threePointPerc/100) %>% 
  gather(key = 'vitalInfo', value = 'value', -Tm, -Player) 

bballLong %>% head
```


## Long to wide

Going the reverse direction

```{r long2wide, cache=TRUE, eval=TRUE}
bballLong %>%
  spread(vitalInfo, value) %>% 
  head
```


# Grouping and Summarizing Data
## Grouping and Summarizing Data

When working with data, a very common task is to look at descriptive statistics for various groups.

Using the various functions within <span class='pack'>dplyr</span> and <span class='pack'>magrittr</span> makes this very easy.

```{r groupby, eval=FALSE}

scoringDat %>% 
  group_by(Pos) %>% 
  summarize(meanTrueShooting = mean(trueShooting, na.rm = TRUE))

scoringDat %>% 
  filter(Pos == "C") %>% 
  arrange(desc(trueShooting)) %>% 
  filter(PTS > median(PTS)) %>% 
  select(trueShooting, PTS) %T>%
  plot() %$% 
  cor(trueShooting, PTS)

```


# Your Turn
## Your Turn
?state.x77

Using one pipe sequence 

1. convert state.x77 (a base R object) to a data frame
2. create a new variable called 'Region' that is equal to state.region
3. create a new variable called 'State' that is equal to state.name
4. select only if Population is greater than 1000 (thousands)
5. select Region and variables beginning with I
6. group by region
7. summarise Income, Illiteracy or Both, using the mean function

## Your Turn
```{r yourturnDataManip, eval=FALSE}
state.x77 %>% 
  data.frame %>% 
  mutate(Region = state.region,
         State = state.name) %>% 
  filter(Population > 1000) %>% 
  select(Region, starts_with('I')) %>% 
  group_by(Region) %>% 
  summarise(meanInc=mean(Income),
            meanIll=mean(Illiteracy))
```

# More with pipes
## More with pipes

Recap thus far:

- <span class='pipe'>%>%</span> : Passes the prior to the function after the pipe
    - x <span class='pipe'>%>%</span> f same as f(x)
- Example:

```{r `%>%`}
iris %>% head
head(iris)
```


## More with pipes
<span class='pipe'>%\$%</span>  : Exposes the names in the prior to the function after

- x <span class='pipe'>%\$%</span> y(a, b)  same as y(x\$a, x\$b)
- Example:

```{r `%$%`}
iris %$% lm(Sepal.Length ~ Sepal.Width)
```

## More with pipes
<span class='pipe'>%T>%</span> : Passes the prior to the function after the pipe and what follows

- x <span class='pipe'>%T>%</span> y <span class='pipe'>%>%</span> z is the same as x <span class='pipe'>%>%</span> y & x <span class='pipe'>%>%</span> z
- Example:

```{r Tpipe, fig.width=3, fig.height=3, echo=-1}
library(dplyr)
iris %>% 
  select(Sepal.Length, Sepal.Width) %T>% 
  plot %>%
  summary
```

## More with pipes
Unfortunately the T pipe does not allow for printable results.

- Works:
```{r Tprobs1, eval=FALSE, }
iris %>% select(Sepal.Length, Sepal.Width) %T>% plot %>% summary
```

- Provides no summary:
```{r Tprobs2, eval=FALSE}
iris %>% select(Sepal.Length, Sepal.Width) %T>% summary %>% plot
```

- Somewhat limiting in my opinion.

## More with pipes
<span class='pipe'>%<>%</span> : assigns to former object the operations that follow

- Example:

```{r `%<>%`}
iris2 = iris
iris2 %<>% rnorm(10)
iris2
```



# Piping to other functions
## Piping to other functions

One of the advantages to piping is that it's not limited to dplyr style data management functions.

<span class='emph'>*Any*</span> R function can be potentially piped to, and we've seen several examples so far.

```{r}
data.frame(y=rnorm(100), x=rnorm(100)) %$%
  lm(y ~ x)
```

This facilitates data exploration 

## Piping to other functions
Many newer visualization packages take advantage of piping as well.

htmlwidgets is a package that makes it easy to use R to create javascript visualizations
- i.e. what you see everywhere on the web.

The packages using it typically are pipe-oriented


## Some htmlwidgets packages
- leaflet 
    - Interactive maps with OpenStreetMap
- dygraphs 
    - Interactive time series visualization
- networkD3 
    - Network visualization with D3
- DT 
    - Tabular data via DataTables
- rthreejs 
    - Interactive 3D graphics

## leaflet

```{r leafletExample, echo=-1}
library(leaflet)
leaflet() %>% 
  setView(lat=42.2655, lng=-83.7485, zoom=15) %>% 
  addTiles() %>% 
  addPopups(lat=42.2655, lng=-83.7485, 'Hi!')
```

## dygraphs

Dygraphs requires time-series objects

```{r dygraphdata, fig.height=3}
#use current poll data code from home
library(dygraphs)
data(UKLungDeaths)
cbind(ldeaths, mdeaths, fdeaths) %>% 
  dygraph()
```


## networkD3

```{r networkD3initial, echo=FALSE, cache=TRUE}
set.seed(1352)
netlinks = data.frame(source = c(0,0,0,1,1,2,2,3,3,3,4,5,5),
                   target = sample(0:5, 13, replace = T),
                   value = sample(1:10, 13, replace = T))


netnodes = data.frame(name = c('Bobby', 'Janie','Timmie', 'Mary', 'Johnny', 'Billy'),
                      group = c('friend', 'frenemy','frenemy', rep('friend', 3)),
                      size = sample(1:20, 6))
```

```{r networkD3}
library(networkD3)
forceNetwork(Links = netlinks, Nodes = netnodes, Source = "source",
             Target = "target", Value = "value", NodeID = "name",
             Nodesize = "size", Group = "group", opacity = 0.4, legend = T,
             colourScale = JS("d3.scale.category10()"))
```


## data table

```{r datatable}
library(DT)
datatable(select(bball, 1:5), rownames=F)
```

## ggvis
ggvis is a general purpose visualization package

  - the successor to ggplot2 to provide interactivity
  - ggplot2 is still great for static plots



```{r ggvisSetup, cache=TRUE}
bballLong %>% head
```


## ggvis
ggvis works by starting with a base, to which subsequent layers are added, with additional options if needed.

```{r ggvisDemo, eval=FALSE}
library(ggvis)
bballLong %>% 
  group_by(Tm, vitalInfo) %>%
  summarize(avg = mean(value)) %>% 
  ggvis(x=~Tm, y=~avg) %>% 
  layer_points(fill = ~vitalInfo) %>% 
  add_axis("x", grid=F, properties = axis_props(labels=list(angle=90, fill='gray'),
                                                axis=list(stroke=NA),
                                                ticks=list(stroke=NA))
           ) %>% 
  add_axis('y', grid=F)
```

## ggvis
```{r ggvisDemo2, eval=TRUE, echo=FALSE}
library(ggvis)
bballLong %>% 
  group_by(Tm, vitalInfo) %>%
  summarize(avg = mean(value)) %>% 
  ggvis(x=~Tm, y=~avg) %>% 
  layer_points(fill = ~vitalInfo) %>% 
  add_axis("x", grid=F, properties = axis_props(labels=list(angle=90, fill='gray'),
                                                axis=list(stroke=NA),
                                                ticks=list(stroke=NA))
           ) %>% 
  add_axis('y', grid=F)
```


# Your turn
## Your turn
Using ggvis and the data set mtcars, well create a grouped scatterplot without creating any new objects.

1. Make a new variable that called 'amFactor' that is just a factor of the original am, with labels 'auto' and 'manual'
    - factor(am, labels=c('auto', 'manual'))
2. Create your base ggvis
2. Group by the transmission factor variable
    - group_by(amFactor)
3. Make a scatterplot (layer_points) of horsepower (hp) and miles per gallon (mpg)
    - fill =~ amFactor
4. add layer_smooths
    - stroke =~ amFactor

## Your turn
```{r ggvisYourTurn, fig.align='center'}
mtcars %>% 
  mutate(amFactor = factor(am, labels=c('auto', 'manual'))) %>% 
  group_by(amFactor) %>%
  ggvis(x=~wt, y=~mpg) %>%
  layer_points(fill=~amFactor) %>%
  layer_smooths(stroke=~amFactor)
```

## For fun
Add a little waggle to your plot.
```{r ggvisFun, eval=FALSE}
span <- waggle(0.5, 2)
mtcars %>% 
  mutate(amFactor = factor(am, labels=c('auto', 'manual'))) %>% 
  group_by(amFactor) %>%
  ggvis(x=~wt, y=~mpg) %>%
  layer_points(fill=~amFactor) %>%
  layer_smooths(stroke=~amFactor, span=span)
```



## Wrap up
Think of these packages as organizational tools.

Use them to bring clarity to code.

With more use, the easier it gets, and the more you can do.

## Thanks!
<table class='acknowledge'>
<tr>
<td style='font-size:12pt'>Michael Clark <br> Advanced Research Computing <br> Consulting for Statistics, Computing & Analytics Research <br> University of Michigan</td>

<td style='text-align:right; font-size:12pt'>Seth Berry<br> Notre Dame Research<br> Center for Social Research<br> University of Notre Dame</td>
</tr>
</table>




## Further
