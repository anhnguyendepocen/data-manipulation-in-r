---
title: "Ceci n'est pas une %>%: <br>Exploring Your Data with R"
author: ""

date: "Fall, 2015"
output: 
  ioslides_presentation: 
    smaller: no
    widescreen: yes
    css: slideStyles.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning=FALSE, R.options=list(width=120))
library(dplyr); library(magrittr)
```


## Goals
- Introduce newer approaches to data wranging, scrubbing, manipulation etc.

- Show the benefits of piping code

- Put it all together with some newer visualization packages 


## Outline 
- Newer approaches to data wrangling
    - Introduction to plyr dplyr and tidyr
    - Subsetting rows
    - Subsetting columns
    - Reshaping data
    - Generating new data
    - Grouping and summarizing

- Nothin's gonna stop the flow
    - Piping with the magrittr package

- Quick interactive visualizations
    - Using *yr packages, piping and visualization
    - ggvis
    - htmlwidgets
    
    

# Newer approaches to <br> data wrangling
## Newer approaches to data wrangling
- A starting example

- Let's say we want to select from our data only the following variables
    - The variables X1:X10, which are not all together, and there are many more 'X' columns
    - The variables var1 and var2, which are the only 'var' variables in the data
    - Any variable that starts with 'XYZ'
    
- How might we go about this?

## Some base R approaches

- Tedious, or typically two steps just to get the columns you want.

```{r baseRexample1, eval=FALSE}
# numeric indexes; not conducive to readibility or reproducibility
newData = oldData[,c(1,2,3,4, etc.)]

# explicitly by name; fine if only a handful
newData = oldData[,c('X1', 'X2', etc.)]

# two step with grep; regex difficult to read/understand
cols = c(paste0('X', 1:10), 'var1', 'var2', grep(colnames(oldData), '^XYZ', value=T))
newData = oldData[,cols]
# or via subset
newData = subset(oldData, select = cols)
```

## More
- What if you also want observations where Z is 'Yes', Q is 'No', and only the last 50 of those results, ordered by var1 (descending)?

```{r baseRexample2, eval=FALSE}
newData = newData[oldData$Z == 'Yes' & oldData$Q == 'No',]
newData = tail(newData, 50)
newData = newdata[order(newdata$var1, decreasing=T),]
```

## An alternative

```{r pipeExample, eval=FALSE}
newData = oldData %>% 
  filter(Z == 'Yes', Q == 'No') %>% 
  select(num_range('X', 1:10), contains('var'), starts_with('XYZ')) %>% 
  tail(50) %>% 
  arrange(desc(var1))
```

## An alternative

- Even though the initial base R approach depicted is probably more concise than many would do on their own, it still is: 
    - noisier
    - less legible
    - less amenable to additional data changes
    - requires esoteric knowledge (e.g. regular expressions)

# Another example...

## Start with a string, end with a map

```{r wikileafletNoEval, eval=FALSE}
packs = c('magrittr', 'rvest', 'dplyr', 'stringr' ,'leaflet', 'ggvis')
sapply(packs, library, character.only=T)

# a color palette to be used later
pal = colorNumeric(palette = c('Red', 'White', 'Navy'), test0$popDiff)  

wikiURL = 'https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population'

# Let's go!
wikiURL %>% 
  read_html %>%                                                                          # parse the html
  html_node(css='.wikitable.sortable') %>%                                          # grab a class of object
  html_table %>%                                                                    # convert table to data.frame
  sapply(function(x) repair_encoding(as.character(x), 'UTF-8')) %>%                 # repair encoding; makes a matrix
  data.frame %>%                                                                    # back to df
  mutate(City = str_replace(City, '\\[(.*?)\\]', ''),                               # remove footnotes
         latlon = sapply(str_split(Location, '/'), last),                           # split up location (3 parts)
         latlon = str_extract_all(latlon, '[-|[0-9]]+\\.[0-9]+'),                   # grab any that start with - or number
         lat = sapply(latlon, first),                                               # grab latitudes
         lon = sapply(latlon, nth, 2),                                              # grab longitude
         population2014 = as.numeric(str_replace_all(X2014.estimate, ',', '')),     # remove commas from numbers (why do people do this?)
         population2010 = as.numeric(str_replace_all(X2010.Census, ',', '')),       # same for 2010
         popDiff  = round(population2014/population2010 - 1, 2)*100) %>%            # create percentage difference
```

## Cont'd.

```{r wikileafletNoEval2, eval=FALSE}
  select(-latlon, -Location) %>%                                                    # remove stuff we wouldn't ever use
  filter(as.numeric(as.character(X2014.rank)) <= 50)  %>%                           # top 50
  leaflet %>%                                                                       # map out
  addProviderTiles("CartoDB.DarkMatterNoLabels") %>% 
  setView(-94, 35, zoom = 4) %>% 
  addCircleMarkers(~lon, ~lat,
                   radius=  ~scales::rescale(popDiff, c(1, 10)),
                   fillColor=  ~pal(popDiff), stroke = FALSE, fillOpacity = .85,
                   popup=  ~paste(City, paste0(popDiff, '%')))
```



## And the result...

```{r wikileaflet, eval=TRUE, echo=FALSE}
# packs = c('magrittr', 'rvest', 'dplyr', 'stringr' ,'leaflet', 'ggvis')
# sapply(packs, library, character.only=T); DONT USE
library(magrittr); library(rvest); library(dplyr); library(stringr);
library(leaflet)

'https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population' %>% 
  read_html %>% 
  html_node(css='.wikitable.sortable') %>% 
  html_table %>% 
  sapply(function(x) repair_encoding(as.character(x), 'UTF-8'), simplify=F) %>%
  data.frame %>%  
  mutate(City = str_replace(City, '\\[(.*?)\\]', ''),
         latlon = sapply(str_split(Location, '/'), last), 
         latlon = str_extract_all(latlon, '[-|[0-9]]+\\.[0-9]+'), 
         lat = sapply(latlon, first),
         lon = sapply(latlon, nth, 2), 
         population2014 = as.numeric(str_replace_all(X2014.estimate, ',', '')),
         population2010 = as.numeric(str_replace_all(X2010.Census, ',', '')),
         popDiff  = round(population2014/population2010 - 1, 2)*100) %T>% 
  select(-latlon, -Location) %>% 
  filter(as.numeric(as.character(X2014.rank)) <= 50)  %>% 
  leaflet %>% 
  addProviderTiles("CartoDB.DarkMatterNoLabels") %>% 
  setView(-94, 35, zoom = 4) %>% 
  addCircleMarkers(~lon, ~lat,
                   radius=  ~scales::rescale(popDiff, c(2, 11)),
                   fillColor=  ~colorNumeric(palette = c('Red', 'White', 'Navy'), popDiff)(popDiff), 
                   stroke = FALSE, fillOpacity = .85,
                   popup=  ~paste(City, paste0(popDiff, '%')))
```


## 

- In the interests of your own code, the previous is not recommended.
- It serves as an illustration of what's possible.

## Newer approaches to data wrangling
- Over the past couple of years, a handful of packages have been put out that make data management within R noticeably easier
- We will focus on plyr, dplyr, tidyr, and maybe reshape2
- But others, e.g. data.table, take different approaches and may be useful as well
- Newer visualization packages take advantage of these approaches to data manipulation

# A provocation

```{r provocation1, eval=F, echo=T}
c('Ceci', "n'est", 'pas', 'une', 'pipe!') %>%
{
  .. <-  . %>%
    if (length(.) == 1)  .
    else paste(.[1], '%>%', ..(.[-1]))
  ..(.)
} 
```

# 

```{r provocation2, eval=T, echo=T}
c('Ceci', "n'est", 'pas', 'une', 'pipe!') %>%
{
  .. <-  . %>%
    if (length(.) == 1)  .
    else paste(.[1], '%>%', ..(.[-1]))
  ..(.)
} 
```


# Your turn
## Your turn
- Use a base R dataset, for example iris or state.x77
- As a simple exercise, pipe to something like the summary or cor (if numeric) as follows:

```{r yourturnPipe, eval=FALSE}
data %>% 
  function
```

- If the function you use, has additional arguments you want to try, put those arguments in parentheses

```{r pipewithargs, eval=FALSE}
data %>% 
  function(arg='blah')
```

Note that Ctrl+Shft+m is the shortcut to make the pipe.


# Generating New Data
## Generating New Data

As is often the case, there are times when we want to calculate new variables based upon existing ones, or perhaps make changes to ones we have.

We will typically use mutate or transmute for this.
- mutate appends to current data
- mutate_each will apply a function over multiple columns
- transmute will return only the newly data


```{r basketballDataScrape, eval=TRUE, cache=TRUE, message=FALSE, echo=-1}
library(rvest); library(dplyr); library(magrittr); library(tidyr)
statsTab = read_html("http://www.basketball-reference.com/leagues/NBA_2015_totals.html?lid=header_seasons") %>% 
  html_nodes("table#totals") %>% 
  html_table %>% 
  data.frame %>% 
  filter(Rk != "Rk")

# data is currently all character strings
statsTab %<>% 
  mutate_each(funs(as.numeric), -Player, -Pos, -Tm)   # convert relevant data to numeric

# glimpse(statsTab)
```


## Generating New Data

- A common situation, creating composites of existing variables.

```{r mutate, cache=TRUE}
statsTab = statsTab %>% 
  mutate(trueShooting = round(PTS / (2 * (FGA + (.44 * FTA))), 2),
         effectiveFG = round((FG + (.5 * X3P)) / FGA, 2), 
         shootingDif = trueShooting - FG.)

summary(select(statsTab, shootingDif))
```



## Generating New Data


```{r, R.options=list(width=120), eval=FALSE, echo=FALSE}
## NOT SURE WHAT THIS WAS ABOUT
statsTab %>% arrange(desc(effectiveFG)) %>% head
```


- Sometimes we want to combine (or split) variables...

```{r tidyrUnite, eval=TRUE}
library(tidyr)
statsTab %>% 
  unite("posTeam", Pos, Tm) %>% 
  select(1:5) %>% 
  head
```

- We will go a bit deeper into this in bit.

# Filtering Observations
## Filtering Observations

- Recall this bit of code?

```{r statstabRecall, eval=FALSE}
statsTab = html("http://www.basketball-reference.com/leagues/NBA_2015_totals.html?lid=header_seasons") %>% 
  html_nodes("table#totals") %>% 
  html_table %>% 
  data.frame %>% 
  filter(Rk != "Rk")
```

- You will notice the filter line at the end.

- We sometimes want to see a very specific portion of the data.

```{r filter, eval=FALSE}
statsTab %>% 
  filter(Age > 35, Pos == "SF" | Pos == "PF")
```


```{r uniteFilterArrange, eval=FALSE}
statsTab %>% 
  unite_("posTeam", c("Pos", "Tm")) %>% 
  filter(posTeam == "PF_SAS") %>% 
  arrange(desc(PTS/PF))
```

# Selecting Variables
## Selecting Variables

- There are times when you do not want to look at the entire dataset, but instead want to focus on a few key variables.

- Although this is easily handled in base (as shown earlier), it can more clearly accomplished using select in dplyr

- The following lets us look at the data clearly, without having to create objects, use quotes etc.

```{r select1, eval=FALSE}
statsTab %>% 
  select(Player, Tm, Pos, MP, trueShooting, effectiveFG, PTS) %>% 
  summary
```

## Selecting Variables
- That works great, but now we need to drop some of those variables to look at correlations.

```{r select2, eval=FALSE}
scoringDat = statsTab %>% 
  select(Player, Tm, Pos, MP, trueShooting, effectiveFG, PTS)

scoringDat %>% 
  select(-Player, -Tm, -Pos) %>% 
  cor(use='complete') %>%
  corrplot::corrplot.mixed()
```

## Selecting Variables
- Sometimes, we have a lot of variables to select. If they have a common naming scheme, this becomes very easy.

```{r select3, eval=FALSE}
statsTab %>% 
  select(Player, contains("3P"), ends_with("RB")) %>% 
  arrange(desc(X3P.1, TRB)) %>% 
  head
```

# Reshaping Data
## Reshaping Data

- Depending upon your analytical or visualization needs, sometimes you need to reshape your data.

- Reshaping can take many forms. You might need to reshape your data from wide format to long format.

- Or, maybe you need to split or combine variables.

- Either way, R has you covered.

## Wide to Long

- We are going to use the tidyr package to make this data go from wide to long.
- The function of note is gather
    - key is the new variable name
    - value is the name of the 

```{r wide2long, eval=TRUE, cache=TRUE}
library(tidyr)

statsTabLong = statsTab %>% 
  select(Player, Tm, FG., X3P, X2P.1, trueShooting, effectiveFG) %>%
  rename(fieldGoalPerc = FG., threePointPerc = X3P, twoPointPerc = X2P.1) %>% 
  mutate(threePointPerc = threePointPerc/100) %>% 
  gather(key = 'vitalInfo', value = 'value', -Tm, -Player) 

statsTabLong %>% head

# save vis for later
# 
# ggvisCleanTheme = axis_props(grid = list(stroke = "white"), 
#                              axis = list(stroke = "white"))
# 
#   group_by(Tm, vitalInfo) %>%
#   summarize(avg = mean(value)) %>% 
#   ggvis(~Tm, ~avg) %>% 
#   group_by(vitalInfo) %>%
#   layer_points(fill = ~vitalInfo) %>% 
#   group_by(vitalInfo) %>% 
#   layer_lines(stroke = ~vitalInfo) %>% 
#   add_axis("x", properties = ggvisCleanTheme)
```


## Long to wide

- Going the reverse direction

```{r long2wide, cache=TRUE, eval=TRUE}
statsTabLong %>%
  spread(vitalInfo, value) %>% 
  head
```


# Grouping and Summarizing Data
## Grouping and Summarizing Data

- When working with data, a very common task is to look at descriptive statistics for various groups.

- Using the various functions within dplyr and magrittr makes this very easy.

```{r groupby, eval=FALSE}

scoringDat %>% 
  group_by(Pos) %>% 
  summarize(meanTrueShooting = mean(trueShooting, na.rm = TRUE))

scoringDat %>% 
  filter(Pos == "C") %>% 
  arrange(desc(trueShooting)) %>% 
  filter(PTS > median(PTS)) %>% 
  select(trueShooting, PTS) %T>%
  plot() %$% 
  cor(trueShooting, PTS)

```


# Your Turn
## Your Turn
?state.x77

Using one pipe sequence 

1. convert state.x77 (a base R object) to a data frame
2. create a new variable called 'Region' that is equal to state.region
2. create a new variable called 'State' that is equal to state.name
3. select only if Population is greater than 1000 (thousands)
3. select Region and variables beginning with I
4. group by region
5. summarise Income, Illiteracy or Both, using the mean function

## Your Turn
```{r yourturnDataManip, eval=FALSE}
state.x77 %>% 
  data.frame %>% 
  mutate(Region = state.region,
         State = state.name) %>% 
  filter(Population > 1000) %>% 
  select(Region, starts_with('I')) %>% 
  group_by(Region) %>% 
  summarise(meanInc=mean(Income),
            meanIll=mean(Illiteracy))
```

# More with pipes
## More with pipes

- Recap thus far
- %>% : Passes the prior to the function after the pipe
    - x %>% f same as f(x)
- Example

```{r `%>%`}
iris %>% head
head(iris)
```


## More with pipes


- \%\$\%  : Exposes the names in the prior to the function after
    - x %\$% y(a, b)  same as y(x\$a, x\$b)
- Example

```{r `%$%`}
iris %$% lm(Sepal.Length ~ Sepal.Width)
```

## More with pipes
- %T>% : Passes the prior to the function after the pipe and what follows
    - x %T>% y %>% z == x %>% y 
- Example

```{r Tpipe, fig.width=3, fig.height=3, echo=-1}
library(dplyr)
iris %>% 
  select(Sepal.Length, Sepal.Width) %T>% 
  plot %>%
  summary
```

## More with pipes
- Unfortunately the T pipe does not allow for printable results.

- Works
```{r Tprobs1, eval=FALSE, }
iris %>% select(Sepal.Length, Sepal.Width) %T>% plot %>% summary
```

- Provides no summary.
```{r Tprobs2, eval=FALSE}
iris %>% select(Sepal.Length, Sepal.Width) %T>% summary %>% plot
```

- Very limiting in my opinion

## More with pipes
- %<>% : assigns to former object the operations that follow

- Example

```{r `%<>%`}
iris2 = iris
iris2 %>% summary
iris2 %<>% rnorm(10)
iris2
```



# Piping to other functions
## Piping to other functions

- One of the advantages to piping is that it's not limited to dplyr style data management

- *Any* R function can be potentially piped to, and we've seen several examples so far.

```{r}
data.frame(y=rnorm(100), x=rnorm(100)) %$%
  lm(y ~ x)
```

- This facilitates data exploration 

## Piping to other functions
- Many newer visualization packages take advantage of piping as well.
- htmlwidgets is a package that makes it easy to use R to create javascript visualizations
    - i.e. what you see everywhere on the web.
- The packages using it typically are pipe-oriented


## Some htmlwidgets packages
- leaflet 
    - Interactive maps with OpenStreetMap
- dygraphs 
    - Interactive time series visualization
- networkD3 
    - Network visualization with D3
- sparkline 
    - Small inline charts
- DT 
    - Tabular data via DataTables
- rthreejs 
    - Interactive 3D graphics

## leaflet

```{r leafletExample, echo=-1}
library(leaflet)
leaflet() %>% 
  setView(lat=42.2655, lng=-83.7485, zoom=15) %>% 
  addTiles() %>% 
  addPopups(lat=42.2655, lng=-83.7485, 'Hi!')
```

## dygraphs

- Dygraphs requires time-series objects

```{r dygraphdata, fig.height=3}
#use current poll data code from home
library(dygraphs)
data(UKLungDeaths)
cbind(ldeaths, mdeaths, fdeaths) %>% 
  dygraph()
```



## sparkline
```{r sparkline, include=F, cache=FALSE}
library(sparkline)
x = rnorm(100)
```

- Sparklines can be use to convey visual information in a small space
- Inline line graphs `r sparkline(x)`
- Bar charts  
`r sparkline(abs(x), type = 'bar')`  
`r sparkline(x, type = 'bar')`

## data table

```{r datatable}
library(DT)
datatable(select(statsTab, 1:5), rownames=F)
```

## ggvis
- ggvis is a general purpose visualization packages, the successor to ggplot2
    - ggplot2 is still great for static plots

```{r ggvis}
statsTabLong %>% head

# save vis for later
# 
# ggvisCleanTheme = axis_props(grid = list(stroke = "white"), 
#                              axis = list(stroke = "white"))
# 
#   group_by(Tm, vitalInfo) %>%
#   summarize(avg = mean(value)) %>% 
#   ggvis(~Tm, ~avg) %>% 
#   group_by(vitalInfo) %>%
#   layer_points(fill = ~vitalInfo) %>% 
#   group_by(vitalInfo) %>% 
#   layer_lines(stroke = ~vitalInfo) %>% 
#   add_axis("x", properties = ggvisCleanTheme)
```


# Your turn
## Your turn


## Wrap up


<table class='acknowledge'>
<tr>
<td style='font-size:12pt'>Michael Clark <br> Advanced Research Computing <br> Consulting for Statistics, Computing & Analytics Research <br> University of Michigan</td>

<td style='text-align:right; font-size:12pt'>Seth Berry<br> Notre Dame Research<br> Center for Social Research<br> University of Notre Dame</td>
</tr>
</table>




## Further
